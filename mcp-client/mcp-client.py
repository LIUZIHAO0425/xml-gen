import asyncio  
import os
from openai import OpenAI
from dotenv import load_dotenv
from contextlib import AsyncExitStack  #èµ„æºç®¡ç†ï¼Œé€€å‡ºåé‡Šæ”¾èµ„æº

# åŠ è½½ .venvæ–‡ä»¶ï¼Œç¡®ä¿apikeyæ”¶åˆ°ä¿æŠ¤
load_dotenv() 

class MCPClient:
    def __init__(self):
        self.exit_stack = AsyncExitStack()    
        """ åˆå§‹åŒ–é€€å‡ºæ ˆ """
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  #è¯»å–openai key
        self.base_url = os.getenv("BASE_URL")  #è¯»å–base url
        self.model = os.getenv("MODEL")

        required_vars = {
          "OPENAI_API_KEY": self.openai_api_key,
          "BASE_URL": self.base_url,
          "MODEL": self.model,
        }
        #dictï¼Œè¿›è¡Œä¸€ä¸‹æ£€æŸ¥
        for var_name, var_value in required_vars.items():
          if not var_value:
            raise ValueError(f"ç¯å¢ƒå˜é‡é”™è¯¯: {var_name} æœªè®¾ç½®")

        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url) #åˆ›å»ºå®¢æˆ·ç«¯

    async def process_query(self, query:str) -> str:
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ ¹æ®è¾“å…¥çš„éœ€æ±‚ï¼Œæ€»ç»“å†…å®¹ç”Ÿæˆç›¸åº”çš„jsonæ–‡ä»¶"},
            {"role": "user", "content": query},
        ]
        try:
            #å¼€å§‹å¼•å…¥å¤§æ¨¡å‹ï¼Œè°ƒç”¨api
            response = await asyncio.get_event_loop().run_in_executor(   #é˜²æ­¢å µå¡
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                ),
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"è°ƒç”¨å‡ºç°Error: {e}")
              
            
    async def chat_loop(self):
        """ run èŠå¤©å¾ªç¯ """
        print("\nMCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        while True:
            try:
                query = input("è¯·è¾“å…¥é—®é¢˜: ").strip()
                if query.lower() == "quit":
                    print("é€€å‡ºå®¢æˆ·ç«¯")
                    break
                response = await self.process_query(query)
                print(f"\n ğŸ¤–OpenAIï¼š{response}")
            except Exception as e:
                print(f"\n âš ï¸[Error] {e}")

    async def cleanup(self):
        await self.exit_stack.aclose()

async def main():
    client = MCPClient()
    try:
        await client.chat_loop()
    finally:
        await client.cleanup()
   



if __name__ == "__main__":
    asyncio.run(main())